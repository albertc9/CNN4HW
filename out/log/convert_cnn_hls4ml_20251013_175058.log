[Info] Logging to: out/log/convert_cnn_hls4ml_20251013_175058.log
[Info] TF version: 2.20.0
[Info] hls4ml version: 0.8.1
[Info] Using config: {
  "model": "/home/work1/Work/CNN_iCube_FPGA_b/models/10.07.25_15-31_100s_2D_CNN_model_2Layer.h5",
  "sample": "/home/work1/Work/CNN_iCube_FPGA_b/out/X_pkl-filtered_float32_N_4_256_1.npy",
  "labels": null,
  "outdir": "hls_cnn_2d_100s",
  "part": "xcku5p-ffvb676-2-e",
  "backend": "Vitis",
  "io": "io_stream",
  "precision": "ap_fixed<16,2>",
  "reuse": 8,
  "strip_dropout": true,
  "do_build": false,
  "test_batch": 8,
  "eval_maxN": 4096,
  "eval_batch": 256,
  "save_preds": false,
  "preds_out": "preds_eval.npz",
  "task_threshold": 0.5
}
[OK] Model input shape verified: (None, 4, 256, 1)

=== Keras Model Summary ===
Model: "converted_model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 4, 256, 1)]       0         
                                                                 
 conv2d (Conv2D)             (None, 1, 247, 20)        820       
                                                                 
 conv2d_1 (Conv2D)           (None, 1, 238, 10)        2010      
                                                                 
 flatten (Flatten)           (None, 2380)              0         
                                                                 
 dense (Dense)               (None, 1)                 2381      
                                                                 
=================================================================
Total params: 5211 (20.36 KB)
Trainable params: 5211 (20.36 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________

=== Layer Details (Conv2D/Dense) ===
[Conv2D] conv2d filters=20 kernel=(4, 10) stride=(1, 1) padding=valid activation=relu data_format=channels_last
[Conv2D] conv2d_1 filters=10 kernel=(1, 10) stride=(1, 1) padding=valid activation=relu data_format=channels_last
[Dense ] dense units=1 activation=sigmoid

=== HLS Config (compact) ===
{
  "Model": {
    "Precision": "ap_fixed<16,2>",
    "ReuseFactor": 8,
    "Strategy": "Latency",
    "BramFactor": 8000,
    "PipelineStyle": "dataflow",
    "ClockPeriod": 4,
    "IOType": "io_stream"
  },
  "LayerName": {
    "conv2d": {
      "Precision": {
        "result": "ap_fixed<16,2>",
        "weight": "ap_fixed<16,2>",
        "bias": "ap_fixed<16,2>",
        "accum": "ap_fixed<18,4>"
      },
      "ReuseFactor": 8,
      "Strategy": "Latency"
    },
    "conv2d_1": {
      "Precision": {
        "result": "ap_fixed<16,2>",
        "weight": "ap_fixed<16,2>",
        "bias": "ap_fixed<16,2>",
        "accum": "ap_fixed<18,4>"
      },
      "ReuseFactor": 8,
      "Strategy": "Latency"
    },
    "dense": {
      "Precision": {
        "result": "ap_fixed<20,2>",
        "weight": "ap_fixed<16,2>",
        "bias": "ap_fixed<16,2>",
        "accum": "ap_fixed<26,10>"
      },
      "ReuseFactor": 8,
      "Strategy": "Latency"
    }
  }
}

[Step] Converting Keras model → HLS project ...
Interpreting Model
Topology:
Layer name: input_1, layer type: InputLayer, input shapes: [[None, 4, 256, 1]], output shape: [None, 4, 256, 1]
Layer name: conv2d, layer type: Conv2D, input shapes: [[None, 4, 256, 1]], output shape: [None, 1, 247, 20]
Layer name: conv2d_1, layer type: Conv2D, input shapes: [[None, 1, 247, 20]], output shape: [None, 1, 238, 10]
Layer name: flatten, layer type: Reshape, input shapes: [[None, 1, 238, 10]], output shape: [None, np.int64(2380)]
Layer name: dense, layer type: Dense, input shapes: [[None, np.int64(2380)]], output shape: [None, 1]
Creating HLS model
[OK] Conversion done. Project at: hls_cnn_2d_100s
[OK] Updated project.tcl backend to: Vitis

[Step] Compiling HLS C-simulation model ...
Writing HLS project
Done
[OK] C-sim compile done.

>>> Real-batch check:
N=8 | MAE=0.640014 | MaxΔ=0.844726

>>> Single sample check (@ sample path):
Keras: 0.9999996423721313  | HLS: 0.2939453125

>>> Random-input diagnostic (not representative):
MAE=0.445691 | MaxΔ=0.799805
Keras preds (first 5): [6.417337916128762e-18, 0.0018536689458414912, 0.0, 0.0, 0.0]
HLS   preds (first 5): [0.79296875, 0.7568359375, 0.7998046875, 0.380859375, 0.1396484375]

[Level-A] NUMERIC DATASET (per-sample)  N=1341  MAE=0.501504  RMSE=0.556755  MaxΔ=0.879813
[Level-A] Top-50 |Δ| samples (idx, y_keras, y_hls, Δ):
  #  369: 0.999931  vs  0.120117   Δ=0.879813
  #  715: 0.999930  vs  0.120117   Δ=0.879812
  #  764: 0.999924  vs  0.120117   Δ=0.879807
  #  983: 0.996158  vs  0.120117   Δ=0.876041
  #  944: 0.999935  vs  0.124023   Δ=0.875912
  #  453: 0.999928  vs  0.124023   Δ=0.875905
  #  744: 0.999919  vs  0.124023   Δ=0.875896
  # 1052: 0.995919  vs  0.120117   Δ=0.875802
  # 1028: 0.995888  vs  0.120117   Δ=0.875771
  #  893: 0.999937  vs  0.125000   Δ=0.874937
  # 1225: 0.999935  vs  0.125000   Δ=0.874935
  #  248: 0.999921  vs  0.125000   Δ=0.874921
  #  482: 0.995737  vs  0.122070   Δ=0.873667
  #  298: 0.995712  vs  0.122070   Δ=0.873642
  #  125: 0.999999  vs  0.126953   Δ=0.873046
  #  993: 0.999935  vs  0.126953   Δ=0.872982
  # 1091: 0.999934  vs  0.126953   Δ=0.872981
  #  433: 0.999932  vs  0.126953   Δ=0.872979
  # 1108: 0.999929  vs  0.126953   Δ=0.872976
  #  245: 0.999924  vs  0.126953   Δ=0.872971
  #  526: 0.996218  vs  0.124023   Δ=0.872194
  # 1134: 0.999936  vs  0.128906   Δ=0.871030
  # 1138: 0.999935  vs  0.128906   Δ=0.871029
  # 1264: 0.999932  vs  0.128906   Δ=0.871025
  #  860: 0.995919  vs  0.125000   Δ=0.870919
  #  941: 0.996165  vs  0.126953   Δ=0.869212
  # 1173: 0.996108  vs  0.126953   Δ=0.869155
  #  142: 0.999999  vs  0.130859   Δ=0.869140
  #   99: 0.999999  vs  0.130859   Δ=0.869139
  #  842: 0.999932  vs  0.130859   Δ=0.869072
  # 1049: 0.996969  vs  0.128906   Δ=0.868062
  #  592: 0.999999  vs  0.132812   Δ=0.867186
  #  423: 0.999999  vs  0.132812   Δ=0.867186
  # 1055: 0.996243  vs  0.130859   Δ=0.865384
  # 1300: 0.999999  vs  0.134766   Δ=0.865233
  #  105: 0.999999  vs  0.135742   Δ=0.864257
  #  397: 0.999938  vs  0.135742   Δ=0.864196
  # 1250: 0.999935  vs  0.135742   Δ=0.864193
  #  357: 0.995961  vs  0.132812   Δ=0.863148
  #  386: 0.995838  vs  0.132812   Δ=0.863025
  # 1044: 0.999942  vs  0.137695   Δ=0.862247
  # 1260: 0.999937  vs  0.137695   Δ=0.862242
  # 1251: 0.999935  vs  0.137695   Δ=0.862240
  # 1163: 0.996692  vs  0.134766   Δ=0.861926
  #  945: 0.996516  vs  0.134766   Δ=0.861750
  # 1155: 0.996445  vs  0.134766   Δ=0.861679
  #  996: 0.996264  vs  0.134766   Δ=0.861499
  #  422: 0.996226  vs  0.134766   Δ=0.861461
  #  800: 0.999944  vs  0.139648   Δ=0.860296
  #  802: 0.999938  vs  0.139648   Δ=0.860290
[Level-A] Saved CSV comparison (all 1341 samples, sorted by |Δ|) to: out/error_analysis/level_a_comparison_20251013_175058.csv
[Info] Level-B skipped: CONFIG['labels'] is None.
