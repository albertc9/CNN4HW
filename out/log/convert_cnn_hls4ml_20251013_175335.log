[Info] Logging to: out/log/convert_cnn_hls4ml_20251013_175335.log
[Info] TF version: 2.20.0
[Info] hls4ml version: 0.8.1
[Info] Using config: {
  "model": "/home/work1/Work/CNN_iCube_FPGA_b/models/10.07.25_15-31_100s_2D_CNN_model_2Layer.h5",
  "sample": "/home/work1/Work/CNN_iCube_FPGA_b/out/X_pkl-filtered_float32_N_4_256_1.npy",
  "labels": null,
  "outdir": "hls_cnn_2d_100s",
  "part": "xcku5p-ffvb676-2-e",
  "backend": "Vitis",
  "io": "io_stream",
  "precision": "ap_fixed<16,2>",
  "reuse": 8,
  "strip_dropout": true,
  "do_build": false,
  "test_batch": 8,
  "eval_maxN": 4096,
  "eval_batch": 256,
  "save_preds": false,
  "preds_out": "preds_eval.npz",
  "task_threshold": 0.5
}
[OK] Model input shape verified: (None, 4, 256, 1)

=== Keras Model Summary ===
Model: "converted_model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 4, 256, 1)]       0         
                                                                 
 conv2d (Conv2D)             (None, 1, 247, 20)        820       
                                                                 
 conv2d_1 (Conv2D)           (None, 1, 238, 10)        2010      
                                                                 
 flatten (Flatten)           (None, 2380)              0         
                                                                 
 dense (Dense)               (None, 1)                 2381      
                                                                 
=================================================================
Total params: 5211 (20.36 KB)
Trainable params: 5211 (20.36 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________

=== Layer Details (Conv2D/Dense) ===
[Conv2D] conv2d filters=20 kernel=(4, 10) stride=(1, 1) padding=valid activation=relu data_format=channels_last
[Conv2D] conv2d_1 filters=10 kernel=(1, 10) stride=(1, 1) padding=valid activation=relu data_format=channels_last
[Dense ] dense units=1 activation=sigmoid

=== HLS Config (compact) ===
{
  "Model": {
    "Precision": "ap_fixed<16,2>",
    "ReuseFactor": 8,
    "Strategy": "Latency",
    "BramFactor": 8000,
    "PipelineStyle": "dataflow",
    "ClockPeriod": 4,
    "IOType": "io_stream"
  },
  "LayerName": {
    "conv2d": {
      "Precision": {
        "result": "ap_fixed<16,2>",
        "weight": "ap_fixed<16,2>",
        "bias": "ap_fixed<16,2>",
        "accum": "ap_fixed<18,4>"
      },
      "ReuseFactor": 8,
      "Strategy": "Latency"
    },
    "conv2d_1": {
      "Precision": {
        "result": "ap_fixed<16,2>",
        "weight": "ap_fixed<16,2>",
        "bias": "ap_fixed<16,2>",
        "accum": "ap_fixed<18,4>"
      },
      "ReuseFactor": 8,
      "Strategy": "Latency"
    },
    "dense": {
      "Precision": {
        "result": "ap_fixed<16,6>",
        "weight": "ap_fixed<16,2>",
        "bias": "ap_fixed<16,2>",
        "accum": "ap_fixed<26,10>"
      },
      "ReuseFactor": 8,
      "Strategy": "Latency"
    }
  }
}

[Step] Converting Keras model → HLS project ...
Interpreting Model
Topology:
Layer name: input_1, layer type: InputLayer, input shapes: [[None, 4, 256, 1]], output shape: [None, 4, 256, 1]
Layer name: conv2d, layer type: Conv2D, input shapes: [[None, 4, 256, 1]], output shape: [None, 1, 247, 20]
Layer name: conv2d_1, layer type: Conv2D, input shapes: [[None, 1, 247, 20]], output shape: [None, 1, 238, 10]
Layer name: flatten, layer type: Reshape, input shapes: [[None, 1, 238, 10]], output shape: [None, np.int64(2380)]
Layer name: dense, layer type: Dense, input shapes: [[None, np.int64(2380)]], output shape: [None, 1]
Creating HLS model
[OK] Conversion done. Project at: hls_cnn_2d_100s
[OK] Updated project.tcl backend to: Vitis

[Step] Compiling HLS C-simulation model ...
Writing HLS project
Done
[OK] C-sim compile done.

>>> Real-batch check:
N=8 | MAE=0.000976235 | MaxΔ=0.000976443

>>> Single sample check (@ sample path):
Keras: 0.9999996423721313  | HLS: 0.9990234375

>>> Random-input diagnostic (not representative):
MAE=0.62439 | MaxΔ=0.999023
Keras preds (first 5): [5.530547035807041e-27, 0.0, 0.0, 1.3041247572101969e-25, 6.521757856808432e-32]
HLS   preds (first 5): [0.9990234375, 0.0, 0.0, 0.9990234375, 0.9990234375]

[Level-A] NUMERIC DATASET (per-sample)  N=1341  MAE=0.00575386  RMSE=0.0183348  MaxΔ=0.159594
[Level-A] Top-50 |Δ| samples (idx, y_keras, y_hls, Δ):
  #  651: 0.343335  vs  0.502930   Δ=0.159594
  #  555: 0.431917  vs  0.584961   Δ=0.153044
  # 1317: 0.433640  vs  0.573242   Δ=0.139602
  # 1100: 0.493749  vs  0.622070   Δ=0.128321
  # 1114: 0.450051  vs  0.573242   Δ=0.123191
  #  967: 0.624271  vs  0.746094   Δ=0.121822
  # 1007: 0.291231  vs  0.407227   Δ=0.115995
  # 1076: 0.613093  vs  0.721680   Δ=0.108587
  # 1080: 0.700116  vs  0.807617   Δ=0.107501
  # 1010: 0.649204  vs  0.754883   Δ=0.105679
  #  618: 0.337382  vs  0.441406   Δ=0.104024
  #  580: 0.688860  vs  0.790039   Δ=0.101179
  #  354: 0.700349  vs  0.799805   Δ=0.099455
  #  484: 0.168075  vs  0.265625   Δ=0.097550
  #  366: 0.762560  vs  0.859375   Δ=0.096815
  #  650: 0.718955  vs  0.814453   Δ=0.095498
  #  943: 0.424747  vs  0.518555   Δ=0.093807
  # 1006: 0.748926  vs  0.841797   Δ=0.092871
  #   74: 0.524224  vs  0.614258   Δ=0.090034
  #  173: 0.234275  vs  0.324219   Δ=0.089944
  # 1224: 0.695411  vs  0.785156   Δ=0.089745
  # 1112: 0.747747  vs  0.834961   Δ=0.087214
  #  530: 0.399053  vs  0.484375   Δ=0.085322
  # 1165: 0.772717  vs  0.857422   Δ=0.084705
  # 1310: 0.682507  vs  0.765625   Δ=0.083118
  #   36: 0.502098  vs  0.584961   Δ=0.082863
  # 1060: 0.763881  vs  0.838867   Δ=0.074986
  # 1101: 0.702253  vs  0.776367   Δ=0.074115
  #   44: 0.806407  vs  0.879883   Δ=0.073476
  # 1025: 0.746070  vs  0.819336   Δ=0.073266
  # 1149: 0.816473  vs  0.889648   Δ=0.073176
  #  350: 0.811305  vs  0.881836   Δ=0.070531
  #  147: 0.109876  vs  0.177734   Δ=0.067858
  # 1315: 0.803424  vs  0.866211   Δ=0.062787
  # 1068: 0.797739  vs  0.859375   Δ=0.061636
  # 1023: 0.841677  vs  0.902344   Δ=0.060666
  #  528: 0.837727  vs  0.897461   Δ=0.059734
  #  634: 0.846142  vs  0.905273   Δ=0.059131
  #   21: 0.196866  vs  0.255859   Δ=0.058994
  #  421: 0.789339  vs  0.847656   Δ=0.058318
  # 1016: 0.838573  vs  0.894531   Δ=0.055958
  #  601: 0.859726  vs  0.913086   Δ=0.053360
  #  988: 0.866018  vs  0.918945   Δ=0.052927
  # 1072: 0.855068  vs  0.907227   Δ=0.052159
  #  695: 0.865183  vs  0.916992   Δ=0.051809
  #   14: 0.142789  vs  0.194336   Δ=0.051547
  # 1001: 0.840090  vs  0.891602   Δ=0.051511
  #  635: 0.835244  vs  0.886719   Δ=0.051474
  # 1102: 0.835465  vs  0.886719   Δ=0.051254
  #  168: 0.720704  vs  0.771484   Δ=0.050780
[Level-A] Saved CSV comparison (all 1341 samples, sorted by |Δ|) to: out/error_analysis/level_a_comparison_20251013_175335.csv
[Info] Level-B skipped: CONFIG['labels'] is None.
